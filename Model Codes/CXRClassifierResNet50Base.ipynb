{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec766e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.io import imread_collection\n",
    "from skimage.color import rgb2gray\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from skimage.io import imread\n",
    "import glob\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b627daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\all_findings_expert_labels_test_labels.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "image_diagnosis_pairs = list(zip(df[\"Image ID\"], df[\"Abnormal\"]))\n",
    "\n",
    "TARGET_SIZE = (512, 512)\n",
    "\n",
    "def load_dataset_from_directory(dir_path, image_diagnosis_pairs):\n",
    "    image_paths = glob.glob(os.path.join(dir_path, '*.png'))\n",
    "    \n",
    "    paired_data_list = []\n",
    "    for row in image_diagnosis_pairs:\n",
    "        file_name, diagnosis = row\n",
    "\n",
    "        for image_path in image_paths:\n",
    "            image_name = os.path.basename(image_path)\n",
    "            if file_name == image_name:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                image = image.resize(TARGET_SIZE)  \n",
    "                image_array = np.array(image, dtype=np.float32)\n",
    "                paired_data_list.append((image_array, diagnosis, image_name))  \n",
    "                break\n",
    "\n",
    "    image_list = [item[0] for item in paired_data_list]\n",
    "    diagnosis_list = [item[1] for item in paired_data_list]\n",
    "    image_name_list = [item[2] for item in paired_data_list]  \n",
    "    binary_diagnosis_list = [0 if diagnosis == \"NO\" else 1 for diagnosis in diagnosis_list]\n",
    "    \n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(image_list)\n",
    "    binary_diagnosis_dataset = tf.data.Dataset.from_tensor_slices(binary_diagnosis_list)\n",
    "    image_name_dataset = tf.data.Dataset.from_tensor_slices(image_name_list)  \n",
    "    \n",
    "    return tf.data.Dataset.zip((image_dataset, binary_diagnosis_dataset, image_name_dataset))\n",
    "\n",
    "directories = [\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset1',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset2',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset3',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset4',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset5',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset6',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset7',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset8',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset9',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset10',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset11',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset12',\n",
    "    'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset13augment'\n",
    "]\n",
    "\n",
    "datasets = {}\n",
    "for i, dir_path in enumerate(directories, start=1):\n",
    "    dataset = load_dataset_from_directory(dir_path, image_diagnosis_pairs)\n",
    "    datasets[f\"dataset_{i}\"] = dataset\n",
    "    print(f\"Length of dataset_{i}:\", len(dataset))\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e53a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## V E R I F I C A T I O N # T H E # R I G H T # P I X E L S # G O T # R U N ###################\n",
    "################################### O P T I O N A L ### R U N ##################################################\n",
    "################################### B L O C K # 1 ##############################################################\n",
    "\n",
    "third_dataset = datasets[\"dataset_5\"]\n",
    "\n",
    "for image, diagnosis, image_name in third_dataset.take(1):\n",
    "    print(\"Image name:\", image_name)\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Diagnosis:\", diagnosis)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(image.numpy().astype('uint8'))  \n",
    "    plt.title(f\"Image from Dataset - {image_name}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "################## V E R I F I C A T I O N # T H E # R I G H T # P I X E L S # G O T # R U N ###################\n",
    "################################### O P T I O N A L ### R U N ##################################################\n",
    "################################### B L O C K # 2 ##############################################################\n",
    "\n",
    "verification = Image.open(\"D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset5\\\\00009437_005.png\").convert('RGB').resize(TARGET_SIZE)\n",
    "verification_array = np.array(verification, dtype=np.float32)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(verification_array.astype('uint8'))  \n",
    "plt.title(\"Verification Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_dataset = datasets[\"dataset_1\"]\n",
    "\n",
    "for i in range(2, len(datasets) + 1):\n",
    "    concatenated_dataset = concatenated_dataset.concatenate(datasets[f\"dataset_{i}\"])\n",
    "\n",
    "print(len(concatenated_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d51023",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shuffled = concatenated_dataset.shuffle(buffer_size=100)\n",
    "print(len(dataset_shuffled))\n",
    "\n",
    "dataset_batched = dataset_shuffled.batch(64)\n",
    "\n",
    "for images, labels, image_name_dataset in dataset_batched.take(30):\n",
    "    print(\"Labels: \", labels.numpy())\n",
    "\n",
    "################## V E R I F I C A T I O N # T H E # R I G H T # P I X E L S # G O T # R U N ###################\n",
    "################################### O P T I O N A L ### R U N ##################################################\n",
    "\n",
    "#for image_array, diagnosis, image_name in dataset_batched.take(1):\n",
    "#        current_image = image_array[i]\n",
    "#        current_image_name = image_name[i].numpy().decode('utf-8')  # Convert image name to string\n",
    "#        current_diagnosis = diagnosis[i].numpy()\n",
    "\n",
    "#        print(\"Image name:\", current_image_name)\n",
    "#        print(\"Image shape:\", current_image.shape)\n",
    "#        print(\"Diagnosis:\", current_diagnosis)\n",
    "\n",
    "#        plt.figure()\n",
    "#        plt.imshow(current_image.numpy().astype('uint8'))  # Convert pixel values back to uint8\n",
    "#        plt.title(f\"Image from Dataset - {current_image_name}\")\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63747f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_image_name(image_dataset, labels, image_name_dataset):\n",
    "    return (image_dataset, labels)\n",
    "\n",
    "dataset_batched_withoutnames = dataset_batched.map(remove_image_name)\n",
    "\n",
    "for images, labels in dataset_batched_withoutnames.take(1):\n",
    "    print(\"Shape of the first image in the batch:\", images[0].shape)\n",
    "    print(\"Shape of the first label in the batch:\", labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, ResNet101, ResNet152, InceptionResNetV2, DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Activation, BatchNormalization\n",
    "from tensorflow.keras import mixed_precision, layers, models\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "drop_rate = 0.20\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='selu')(base_model.output)\n",
    "conv2 = layers.Conv2D(32, (1, 1), activation='selu')(conv1)\n",
    "conv3 = layers.Conv2D(32, (1, 1), activation='selu')(conv2)\n",
    "\n",
    "flatten = layers.Flatten()(conv3)\n",
    "\n",
    "dense1 = layers.Dense(64, activation='relu')(flatten)\n",
    "drop1 = layers.Dropout(drop_rate)(dense1)\n",
    "\n",
    "dense2 = layers.Dense(64, activation='relu')(drop1)\n",
    "dense3 = layers.Dense(64, activation='relu')(dense2)\n",
    "dense4 = layers.Dense(64, activation='relu')(dense3)\n",
    "dense5 = layers.Dense(64, activation='relu')(dense4)\n",
    "\n",
    "drop2 = layers.Dropout(drop_rate)(dense5)\n",
    "\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(drop2)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=50,  \n",
    "    decay_rate=0.9,\n",
    "    staircase=False)\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7a128",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "history = model.fit(dataset_batched_withoutnames, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## T E S T -- C O D E -- B L O C K ##########################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "test_directory = ['D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\test']\n",
    "\n",
    "csv_path = \"D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\all_findings_expert_labels_test_labels.csv\"\n",
    "df_test = pd.read_csv(csv_path)\n",
    "\n",
    "image_diagnosis_pairs_test = list(zip(df_test[\"Image ID\"], df_test[\"Abnormal\"]))\n",
    "\n",
    "for i in range(25):  \n",
    "    print(image_diagnosis_pairs_test[i])\n",
    "\n",
    "paired_data_list_test = []\n",
    "\n",
    "for dir_path_test in test_directory:\n",
    "    image_paths_test = glob.glob(os.path.join(dir_path_test, '*.png'))\n",
    "\n",
    "    for row in image_diagnosis_pairs_test:\n",
    "        file_name_test, diagnosis_test = row\n",
    "\n",
    "        for image_path_test in image_paths_test:\n",
    "            image_name_test = os.path.basename(image_path_test)\n",
    "            if file_name_test == image_name_test:\n",
    "                image_test = Image.open(image_path_test).convert(\"RGB\")  \n",
    "                image_test = image_test.resize((512, 512))\n",
    "\n",
    "                image_array_test = np.array(image_test, dtype=np.float32)\n",
    "                \n",
    "                paired_data_list_test.append((image_array_test, diagnosis_test))\n",
    "                break\n",
    "\n",
    "image_list_test = [item[0] for item in paired_data_list_test]\n",
    "diagnosis_list_test = [item[1] for item in paired_data_list_test]\n",
    "binary_diagnosis_list_test = [0 if diagnosis == \"NO\" else 1 for diagnosis in diagnosis_list_test]\n",
    "\n",
    "image_testset = tf.data.Dataset.from_tensor_slices(image_list_test)\n",
    "binary_diagnosis_testset = tf.data.Dataset.from_tensor_slices(binary_diagnosis_list_test)\n",
    "\n",
    "testset = tf.data.Dataset.zip((image_testset, binary_diagnosis_testset))\n",
    "\n",
    "print(len(testset))\n",
    "\n",
    "results = model.evaluate(testset.batch(32))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "testset_batched = testset.batch(32)\n",
    "predictions = model.predict(testset_batched)\n",
    "\n",
    "true_labels = np.concatenate([y for x, y in testset_batched], axis=0)\n",
    "\n",
    "uncertain_mask = (predictions > 0.3) & (predictions < 0.49999)\n",
    "uncertain_indices = np.where(uncertain_mask)[0]\n",
    "\n",
    "image_paths = [image_paths_test[i] for i in uncertain_indices]\n",
    "\n",
    "for idx, image_path in zip(uncertain_indices, image_paths):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    enhanced_image = cv2.equalizeHist(image)\n",
    "    enhanced_image_rgb = cv2.cvtColor(enhanced_image, cv2.COLOR_GRAY2RGB)\n",
    "    enhanced_image_rgb = enhanced_image_rgb / 255.0\n",
    "    enhanced_image_rgb = cv2.resize(enhanced_image_rgb, (512, 512))\n",
    "    enhanced_image_rgb = np.expand_dims(enhanced_image_rgb, axis=0) \n",
    "    new_prediction = model.predict(enhanced_image_rgb)\n",
    "    if new_prediction[0, 0] > 0.5:  \n",
    "        predictions[idx] = new_prediction\n",
    "\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "recall = recall_score(true_labels, binary_predictions)\n",
    "precision = precision_score(true_labels, binary_predictions)\n",
    "auc = roc_auc_score(true_labels, predictions)\n",
    "\n",
    "print(f'Updated Accuracy: {accuracy}')\n",
    "print(f'Updated Recall: {recall}')\n",
    "print(f'Updated Precision: {precision}')\n",
    "print(f'Updated AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eabafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "testset_batched = testset.batch(1)\n",
    "\n",
    "for i, (image, label) in enumerate(testset_batched.take(20)):\n",
    "    prediction = model.predict(image)\n",
    "    \n",
    "    predicted_label = (prediction > 0.5).astype(int)\n",
    "    \n",
    "    image_to_show = image.numpy().squeeze()\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image_to_show.astype('uint8'))\n",
    "    plt.title(f'Actual Label: {label.numpy()[0]}\\nPredicted Label: {predicted_label[0][0]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d9211c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leest\\anaconda3\\envs\\CXRGPUtf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "################################################ S A V E -- M O D E L ################################################\n",
    "model.save('model.h5')\n",
    "loaded_model = tf.keras.models.load_model('C:\\\\Users\\\\leest\\\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ad285",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## S H A P -- V I S U A L I Z A T I O N ##########################################\n",
    "\n",
    "!pip install shap --upgrade shap\n",
    "!pip install opencv-python --upgrade\n",
    "!pip install tqdm --upgrade tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "import shap\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "model_path = 'C:\\\\Users\\\\leest\\\\bumblerumble.h5'  \n",
    "original_model = load_model(model_path)\n",
    "\n",
    "model_shap = tf.keras.models.clone_model(original_model)\n",
    "\n",
    "model_shap.set_weights([w.astype('float32') for w in original_model.get_weights()])\n",
    "\n",
    "#img_path = 'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset3\\\\non_COVID (636).png'\n",
    "img_path = 'D:\\\\Deep Learning Project\\\\final\\\\CXRNormalClassifer\\\\correctLabelDataVersion\\\\final\\\\train\\\\trainset3\\\\covid_1752.png'\n",
    "#img_path = 'C:\\\\Users\\\\leest\\\\OneDrive\\\\Desktop\\\\1000_F_441290900_JdXNtu6vcPtYOenFo4Y466GbqdyczOxR.jpg'\n",
    "\n",
    "img = Image.open(img_path).convert('RGB').resize(TARGET_SIZE) \n",
    "img_array = np.array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = img_array.astype(np.float32)\n",
    "\n",
    "import tensorflow as tf\n",
    "output = tf.keras.layers.Lambda(lambda x: tf.cast(x, tf.float32))(original_model.output)\n",
    "new_model = tf.keras.models.Model(inputs=original_model.input, outputs=output)\n",
    "print(img_array.shape)\n",
    "masker = shap.maskers.Image(\"inpaint_telea\", (512, 512, 3)) \n",
    "\n",
    "explainer = shap.Explainer(new_model, masker) \n",
    "\n",
    "shap_values = explainer(img_array)\n",
    "\n",
    "shap.image_plot(shap_values, img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509d8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU",
   "language": "python",
   "name": "cxrgputf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
